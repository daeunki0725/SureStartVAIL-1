{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sarcasm Detection from News Headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.5)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.24.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.5.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries and modules\n",
    "!pip install pandas scikit-learn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pprint\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "np.random.seed(1234)\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure GPU is connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "def parse_data(file):\n",
    "    for l in open(file,'r'):\n",
    "        yield json.loads(l)\n",
    "\n",
    "data1 = pd.read_json(\"Sarcasm_Headlines_Dataset.json\", lines=True)\n",
    "data2 = pd.read_json(\"Sarcasm_Headlines_Dataset_v2.json\", lines=True)\n",
    "data = pd.concat([data1, data2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_link  \\\n",
       "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
       "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
       "2  https://local.theonion.com/mom-starting-to-fea...   \n",
       "3  https://politics.theonion.com/boehner-just-wan...   \n",
       "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
       "\n",
       "                                            headline  is_sarcastic  \n",
       "0  former versace store clerk sues over secret 'b...             0  \n",
       "1  the 'roseanne' revival catches up to our thorn...             0  \n",
       "2  mom starting to fear son's web series closest ...             1  \n",
       "3  boehner just wants wife to listen, not come up...             1  \n",
       "4  j.k. rowling wishes snape happy birthday in th...             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first 5 pieces of data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  is_sarcastic\n",
       "0  former versace store clerk sues over secret 'b...             0\n",
       "1  the 'roseanne' revival catches up to our thorn...             0\n",
       "2  mom starting to fear son's web series closest ...             1\n",
       "3  boehner just wants wife to listen, not come up...             1\n",
       "4  j.k. rowling wishes snape happy birthday in th...             0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove \"article_link\" column\n",
    "del data[\"article_link\"]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headline        0.0\n",
       "is_sarcastic    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the data has some null values\n",
    "data[data.isnull()].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55328"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show how many examples we have in our dataset\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X = data[\"headline\"].values\n",
    "y = data[\"is_sarcastic\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49795,) (5533,) (49795,) (5533,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1234)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token=\"OOV\", num_words=100000, filters='!\"#$%&()*+,-./:;<=>@[\\]^_`{|}~ ')\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 1681, 1266, 594, 15601, 46, 4, 3433, 211]]\n"
     ]
    }
   ],
   "source": [
    "# Test the tokenizer\n",
    "print(tokenizer.texts_to_sequences([\"The quick brown fox jumped over the lazy dog.\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the sequences\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "max_seq_len = max(len(x) for x in X_train_seq)\n",
    "X_train_seq = np.array([np.pad(x, (0, max_seq_len - len(x))) for x in X_train_seq])\n",
    "\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "X_test_seq = np.array([np.pad(x, (0, max_seq_len - len(x))) for x in X_test_seq])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 2)           62410     \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 4)                 80        \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                160       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 62,683\n",
      "Trainable params: 62,683\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embed_size = 2\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embed_size, input_shape=[None]),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embed_size)),\n",
    "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1557/1557 - 24s - loss: 0.3452 - accuracy: 0.8382 - val_loss: 0.2214 - val_accuracy: 0.9093\n",
      "Epoch 2/30\n",
      "1557/1557 - 20s - loss: 0.1270 - accuracy: 0.9560 - val_loss: 0.1421 - val_accuracy: 0.9516\n",
      "Epoch 3/30\n",
      "1557/1557 - 20s - loss: 0.0602 - accuracy: 0.9811 - val_loss: 0.1047 - val_accuracy: 0.9691\n",
      "Epoch 4/30\n",
      "1557/1557 - 20s - loss: 0.0323 - accuracy: 0.9899 - val_loss: 0.0938 - val_accuracy: 0.9763\n",
      "Epoch 5/30\n",
      "1557/1557 - 20s - loss: 0.0183 - accuracy: 0.9950 - val_loss: 0.0979 - val_accuracy: 0.9783\n",
      "Epoch 6/30\n",
      "1557/1557 - 20s - loss: 0.0106 - accuracy: 0.9970 - val_loss: 0.0944 - val_accuracy: 0.9819\n",
      "Epoch 7/30\n",
      "1557/1557 - 21s - loss: 0.0073 - accuracy: 0.9981 - val_loss: 0.1055 - val_accuracy: 0.9816\n",
      "Epoch 8/30\n",
      "1557/1557 - 20s - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.1315 - val_accuracy: 0.9816\n",
      "Epoch 9/30\n",
      "1557/1557 - 20s - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.1235 - val_accuracy: 0.9841\n",
      "Epoch 10/30\n",
      "1557/1557 - 20s - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.1297 - val_accuracy: 0.9841\n",
      "Epoch 11/30\n",
      "1557/1557 - 20s - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.1398 - val_accuracy: 0.9825\n",
      "Epoch 12/30\n",
      "1557/1557 - 20s - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.1442 - val_accuracy: 0.9843\n",
      "Epoch 13/30\n",
      "1557/1557 - 21s - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.1438 - val_accuracy: 0.9839\n",
      "Epoch 14/30\n",
      "1557/1557 - 21s - loss: 9.3288e-04 - accuracy: 0.9997 - val_loss: 0.1531 - val_accuracy: 0.9819\n",
      "Epoch 15/30\n",
      "1557/1557 - 21s - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.1692 - val_accuracy: 0.9823\n",
      "Epoch 16/30\n",
      "1557/1557 - 21s - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.1718 - val_accuracy: 0.9832\n",
      "Epoch 17/30\n",
      "1557/1557 - 21s - loss: 6.8594e-04 - accuracy: 0.9997 - val_loss: 0.1704 - val_accuracy: 0.9834\n",
      "Epoch 18/30\n",
      "1557/1557 - 21s - loss: 5.7376e-05 - accuracy: 1.0000 - val_loss: 0.1817 - val_accuracy: 0.9834\n",
      "Epoch 19/30\n",
      "1557/1557 - 21s - loss: 1.7178e-05 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 0.9823\n",
      "Epoch 20/30\n",
      "1557/1557 - 21s - loss: 4.3798e-06 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 0.9832\n",
      "Epoch 21/30\n",
      "1557/1557 - 21s - loss: 1.8813e-06 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 0.9828\n",
      "Epoch 22/30\n",
      "1557/1557 - 21s - loss: 9.7961e-07 - accuracy: 1.0000 - val_loss: 0.2219 - val_accuracy: 0.9828\n",
      "Epoch 23/30\n",
      "1557/1557 - 21s - loss: 4.7266e-07 - accuracy: 1.0000 - val_loss: 0.2313 - val_accuracy: 0.9828\n",
      "Epoch 24/30\n",
      "1557/1557 - 21s - loss: 2.4471e-07 - accuracy: 1.0000 - val_loss: 0.2433 - val_accuracy: 0.9832\n",
      "Epoch 25/30\n",
      "1557/1557 - 21s - loss: 1.1568e-07 - accuracy: 1.0000 - val_loss: 0.2559 - val_accuracy: 0.9832\n",
      "Epoch 26/30\n",
      "1557/1557 - 21s - loss: 5.9514e-08 - accuracy: 1.0000 - val_loss: 0.2697 - val_accuracy: 0.9834\n",
      "Epoch 27/30\n",
      "1557/1557 - 22s - loss: 2.9189e-08 - accuracy: 1.0000 - val_loss: 0.2871 - val_accuracy: 0.9826\n",
      "Epoch 28/30\n",
      "1557/1557 - 22s - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.2515 - val_accuracy: 0.9817\n",
      "Epoch 29/30\n",
      "1557/1557 - 21s - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.2212 - val_accuracy: 0.9839\n",
      "Epoch 30/30\n",
      "1557/1557 - 21s - loss: 4.0307e-04 - accuracy: 0.9999 - val_loss: 0.2246 - val_accuracy: 0.9821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1f60865518>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train_seq, y_train, epochs=30, validation_data=(X_test_seq, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9821073558648111\n"
     ]
    }
   ],
   "source": [
    "# Predict the testing data to find accuracy\n",
    "pred = model.predict(X_test_seq).round()\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
